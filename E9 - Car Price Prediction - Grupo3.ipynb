{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E9 - Grupo 3\n",
    "## Car Price Prediction\n",
    "Predecir si el precio de un carro es bajo o alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15           0           0          1  \n",
       "47           0           0          1  \n",
       "85           0           0          1  \n",
       "141          1           0          1  \n",
       "226          0           1          0  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('dataTrain_carListings.csv')\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
    "data = data.drop(['Model', 'Price'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 10)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['HighPrice']\n",
    "X = data.drop(['HighPrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.1\n",
    "Estimar un árbol de decisión manualmente utilizando decision trees notebook (cada variable separada en 10 percentiles).\n",
    "\n",
    "Evaluar accuracy en el set de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(X_col, y, split):\n",
    "      \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función que encuentra el mejor punto de corte para cada variable predictora\n",
    "Identificar el punto de corte para cada variable utilizando el Gini como el criterio de decisión (Es decir el punto de corte de la variable que minimice la probabilidad que un dato en un nodo, seleccionado al azar, esté mal clasificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # For all splits\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear el arbol\n",
    "Identificar primero la variable que haga que el Gini sea inferior. Empezar el árbol por esa variable (primer nivel), quitar esa variable y repetir para encontrar el segundo nivel, tercer nivel ... hasta el máx_depth, que en este caso seleccionaremos como el número de variables que tenemos para los carros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=len(X.columns), num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5780753517930095,\n",
       " 'level': 0,\n",
       " 'split': [1, 52187.63636363637],\n",
       " 'n_samples': 8810,\n",
       " 'gain': 0.23872134898880762,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8391583452211127,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 5606,\n",
       "  'gain': 0.03317687167496233,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.36828644501278773,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 389,\n",
       "   'gain': 0.05908490521197157,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.08,\n",
       "    'level': 3,\n",
       "    'split': [2, 1.0],\n",
       "    'n_samples': 98,\n",
       "    'gain': 0.01707452211653898,\n",
       "    'sl': {'y_pred': 0,\n",
       "     'y_prob': 0.04597701149425287,\n",
       "     'level': 4,\n",
       "     'split': [1, 37722.0],\n",
       "     'n_samples': 85,\n",
       "     'gain': 0.001980228771650633,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.12,\n",
       "      'level': 5,\n",
       "      'split': [1, 33000.0],\n",
       "      'n_samples': 23,\n",
       "      'gain': 0.03456656764785304,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.05555555555555555,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 16,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.3333333333333333,\n",
       "       'level': 6,\n",
       "       'split': [1, 34334.454545454544],\n",
       "       'n_samples': 7,\n",
       "       'gain': 0.40816326530612246,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.75,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 2,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.14285714285714285,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 5,\n",
       "        'gain': 0}}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.03125,\n",
       "      'level': 5,\n",
       "      'split': [1, 49802.09090909091],\n",
       "      'n_samples': 62,\n",
       "      'gain': 0.002167880679847252,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.019230769230769232,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 50,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.14285714285714285,\n",
       "       'level': 6,\n",
       "       'split': [0, 2011.0],\n",
       "       'n_samples': 12,\n",
       "       'gain': 0.019444444444444625,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.2857142857142857,\n",
       "        'level': 7,\n",
       "        'split': [0, 2008.1818181818182],\n",
       "        'n_samples': 5,\n",
       "        'gain': 0.05333333333333318,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.25,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 2,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.4,\n",
       "         'level': 8,\n",
       "         'split': [1, 50074.90909090909],\n",
       "         'n_samples': 3,\n",
       "         'gain': 0.1111111111111111,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.1111111111111111,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 7,\n",
       "        'gain': 0}}}},\n",
       "    'sr': {'y_pred': 0,\n",
       "     'y_prob': 0.3333333333333333,\n",
       "     'level': 4,\n",
       "     'split': [1, 40282.27272727273],\n",
       "     'n_samples': 13,\n",
       "     'gain': 0.3029585798816569,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.7142857142857143,\n",
       "      'level': 5,\n",
       "      'split': [0, 2007.090909090909],\n",
       "      'n_samples': 5,\n",
       "      'gain': 0.05333333333333318,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.75,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 2,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.6,\n",
       "       'level': 6,\n",
       "       'split': [1, 28524.545454545456],\n",
       "       'n_samples': 3,\n",
       "       'gain': 0.4444444444444444,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.75,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 2,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.5,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 1,\n",
       "        'gain': 0}}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.1,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 8,\n",
       "      'gain': 0}}},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.46757679180887374,\n",
       "    'level': 3,\n",
       "    'split': [1, 40957.63636363636],\n",
       "    'n_samples': 291,\n",
       "    'gain': 0.036947257392555666,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 0.5900621118012422,\n",
       "     'level': 4,\n",
       "     'split': [6, 1.0],\n",
       "     'n_samples': 159,\n",
       "     'gain': 0.02113146329703186,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.625,\n",
       "      'level': 5,\n",
       "      'split': [0, 2013.0],\n",
       "      'n_samples': 142,\n",
       "      'gain': 0.026368394549310947,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.5,\n",
       "       'level': 6,\n",
       "       'split': [2, 0.2727272727272805],\n",
       "       'n_samples': 64,\n",
       "       'gain': 0.051724137931034475,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.45,\n",
       "        'level': 7,\n",
       "        'split': [7, 0.6363636363636402],\n",
       "        'n_samples': 58,\n",
       "        'gain': 0.03323389995791143,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.5102040816326531,\n",
       "         'level': 8,\n",
       "         'split': [8, 0.8181818181818201],\n",
       "         'n_samples': 47,\n",
       "         'gain': 0.01993576063290864,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.4772727272727273,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 42,\n",
       "          'gain': 0.015783506385010138},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7142857142857143,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.05333333333333318}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.23076923076923078,\n",
       "         'level': 8,\n",
       "         'split': [1, 27382.272727272728],\n",
       "         'n_samples': 11,\n",
       "         'gain': 0.13388429752066133,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.16666666666666666,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 10,\n",
       "          'gain': 0.029999999999999916}}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.875,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 6,\n",
       "        'gain': 0}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.725,\n",
       "       'level': 6,\n",
       "       'split': [5, 1.0],\n",
       "       'n_samples': 78,\n",
       "       'gain': 0.0674661025831596,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.7887323943661971,\n",
       "        'level': 7,\n",
       "        'split': [1, 15824.363636363636],\n",
       "        'n_samples': 69,\n",
       "        'gain': 0.009295959780745378,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.8888888888888888,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 7,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.765625,\n",
       "         'level': 8,\n",
       "         'split': [1, 31109.09090909091],\n",
       "         'n_samples': 62,\n",
       "         'gain': 0.0036748310146119123,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.8,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 28,\n",
       "          'gain': 0.025510204081632792},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7222222222222222,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 34,\n",
       "          'gain': 0.031272091379246025}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.2727272727272727,\n",
       "        'level': 7,\n",
       "        'split': [1, 39570.545454545456],\n",
       "        'n_samples': 9,\n",
       "        'gain': 0.15123456790123457,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.2,\n",
       "         'level': 8,\n",
       "         'split': [1, 30761.909090909092],\n",
       "         'n_samples': 8,\n",
       "         'gain': 0.03125,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.3333333333333333,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0.375},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.16666666666666666,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 1,\n",
       "         'gain': 0}}}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.3157894736842105,\n",
       "      'level': 5,\n",
       "      'split': [1, 26545.727272727272],\n",
       "      'n_samples': 17,\n",
       "      'gain': 0.0594826165760422,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.6,\n",
       "       'level': 6,\n",
       "       'split': [0, 2012.090909090909],\n",
       "       'n_samples': 3,\n",
       "       'gain': 0.4444444444444444,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.75,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 2,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.5,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 1,\n",
       "        'gain': 0}},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.25,\n",
       "       'level': 6,\n",
       "       'split': [1, 39706.90909090909],\n",
       "       'n_samples': 14,\n",
       "       'gain': 0.027210884353741638,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.21428571428571427,\n",
       "        'level': 7,\n",
       "        'split': [1, 36333.0],\n",
       "        'n_samples': 12,\n",
       "        'gain': 0.02777777777777768,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.3,\n",
       "         'level': 8,\n",
       "         'split': [1, 33505.181818181816],\n",
       "         'n_samples': 8,\n",
       "         'gain': 0.16071428571428586,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.2222222222222222,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 7,\n",
       "          'gain': 0.05442176870748283},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.16666666666666666,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 4,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.5,\n",
       "        'level': 7,\n",
       "        'split': [1, 39838.90909090909],\n",
       "        'n_samples': 2,\n",
       "        'gain': 0.5,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 1,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 1,\n",
       "         'gain': 0}}}}},\n",
       "    'sr': {'y_pred': 0,\n",
       "     'y_prob': 0.3208955223880597,\n",
       "     'level': 4,\n",
       "     'split': [2, 1.0],\n",
       "     'n_samples': 132,\n",
       "     'gain': 0.03762646053006563,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.2711864406779661,\n",
       "      'level': 5,\n",
       "      'split': [8, 1.0],\n",
       "      'n_samples': 116,\n",
       "      'gain': 0.03806292472788064,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.21212121212121213,\n",
       "       'level': 6,\n",
       "       'split': [0, 2013.0],\n",
       "       'n_samples': 97,\n",
       "       'gain': 0.02564376473995028,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.32075471698113206,\n",
       "        'level': 7,\n",
       "        'split': [1, 47544.81818181818],\n",
       "        'n_samples': 51,\n",
       "        'gain': 0.03211378327972264,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.43333333333333335,\n",
       "         'level': 8,\n",
       "         'split': [1, 42028.0],\n",
       "         'n_samples': 28,\n",
       "         'gain': 0.04408163265306131,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.2,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.48148148148148145,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 25,\n",
       "          'gain': 0.04269206349206356}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.2,\n",
       "         'level': 8,\n",
       "         'split': [1, 49035.0],\n",
       "         'n_samples': 23,\n",
       "         'gain': 0.01793987916527673,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.375,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0.1111111111111111},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.15789473684210525,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 17,\n",
       "          'gain': 0.019937386719393685}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.10416666666666667,\n",
       "        'level': 7,\n",
       "        'split': [7, 1.0],\n",
       "        'n_samples': 46,\n",
       "        'gain': 0.013862633900441096,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.041666666666666664,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 22,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.19230769230769232,\n",
       "         'level': 8,\n",
       "         'split': [1, 44316.81818181818],\n",
       "         'n_samples': 24,\n",
       "         'gain': 0.009712509712509587,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.15384615384615385,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 11,\n",
       "          'gain': 0.07438016528925631},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.26666666666666666,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 13,\n",
       "          'gain': 0.02635825712748785}}}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.5714285714285714,\n",
       "       'level': 6,\n",
       "       'split': [1, 43504.454545454544],\n",
       "       'n_samples': 19,\n",
       "       'gain': 0.0945521698984303,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.8333333333333334,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 4,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.47058823529411764,\n",
       "        'level': 7,\n",
       "        'split': [1, 46384.545454545456],\n",
       "        'n_samples': 15,\n",
       "        'gain': 0.03414141414141414,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.3333333333333333,\n",
       "         'level': 8,\n",
       "         'split': [1, 45932.454545454544],\n",
       "         'n_samples': 4,\n",
       "         'gain': 0.125,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.25,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5384615384615384,\n",
       "         'level': 8,\n",
       "         'split': [1, 48078.09090909091],\n",
       "         'n_samples': 11,\n",
       "         'gain': 0.10798898071625357,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.7142857142857143,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.31999999999999984},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.375,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0.2222222222222222}}}}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.6666666666666666,\n",
       "      'level': 5,\n",
       "      'split': [1, 44286.90909090909],\n",
       "      'n_samples': 16,\n",
       "      'gain': 0.057892628205128194,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.4,\n",
       "       'level': 6,\n",
       "       'split': [1, 42771.45454545454],\n",
       "       'n_samples': 3,\n",
       "       'gain': 0.4444444444444444,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.5,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 1,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.25,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 2,\n",
       "        'gain': 0}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.7333333333333333,\n",
       "       'level': 6,\n",
       "       'split': [1, 46815.90909090909],\n",
       "       'n_samples': 13,\n",
       "       'gain': 0.09129332206255286,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.875,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 6,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.5555555555555556,\n",
       "        'level': 7,\n",
       "        'split': [1, 51056.81818181818],\n",
       "        'n_samples': 7,\n",
       "        'gain': 0.4897959183673469,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.2,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 3,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8333333333333334,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 4,\n",
       "         'gain': 0}}}}}}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 0.8743054224947308,\n",
       "   'level': 2,\n",
       "   'split': [0, 2015.0],\n",
       "   'n_samples': 5217,\n",
       "   'gain': 0.014933378976312917,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 0.7348484848484849,\n",
       "    'level': 3,\n",
       "    'split': [6, 1.0],\n",
       "    'n_samples': 1450,\n",
       "    'gain': 0.02449522073718463,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 0.7944839857651246,\n",
       "     'level': 4,\n",
       "     'split': [1, 35886.818181818184],\n",
       "     'n_samples': 1122,\n",
       "     'gain': 0.014757969303423768,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.8589385474860335,\n",
       "      'level': 5,\n",
       "      'split': [8, 1.0],\n",
       "      'n_samples': 714,\n",
       "      'gain': 0.0033895911305698023,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.8420195439739414,\n",
       "       'level': 6,\n",
       "       'split': [1, 19419.363636363636],\n",
       "       'n_samples': 612,\n",
       "       'gain': 0.002622192014060498,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.9122807017543859,\n",
       "        'level': 7,\n",
       "        'split': [7, 1.0],\n",
       "        'n_samples': 112,\n",
       "        'gain': 0.006631791230005679,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.975,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 38,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.868421052631579,\n",
       "         'level': 8,\n",
       "         'split': [1, 16645.727272727272],\n",
       "         'n_samples': 74,\n",
       "         'gain': 0.004642077385033028,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.8979591836734694,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 47,\n",
       "          'gain': 0.009460407069120103},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7931034482758621,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 27,\n",
       "          'gain': 0.016598079561042423}}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.8247011952191236,\n",
       "        'level': 7,\n",
       "        'split': [1, 27144.545454545456],\n",
       "        'n_samples': 500,\n",
       "        'gain': 0.0011101743036838752,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.8532608695652174,\n",
       "         'level': 8,\n",
       "         'split': [5, 1.0],\n",
       "         'n_samples': 182,\n",
       "         'gain': 0.0019562854727689927,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.8712121212121212,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 130,\n",
       "          'gain': 0.005078841315872523},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7962962962962963,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 52,\n",
       "          'gain': 0.03536447186201669}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.80625,\n",
       "         'level': 8,\n",
       "         'split': [1, 29164.545454545456],\n",
       "         'n_samples': 318,\n",
       "         'gain': 0.001990654224238275,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.7333333333333333,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 58,\n",
       "          'gain': 0.015434921796396273},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.8206106870229007,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 260,\n",
       "          'gain': 0.003720873867549379}}}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.9519230769230769,\n",
       "       'level': 6,\n",
       "       'split': [1, 26025.545454545456],\n",
       "       'n_samples': 102,\n",
       "       'gain': 0.0037443792521270475,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.9827586206896551,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 56,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.8958333333333334,\n",
       "        'level': 7,\n",
       "        'split': [1, 31841.818181818184],\n",
       "        'n_samples': 46,\n",
       "        'gain': 0.00524979746151788,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.8260869565217391,\n",
       "         'level': 8,\n",
       "         'split': [1, 30553.545454545456],\n",
       "         'n_samples': 21,\n",
       "         'gain': 0.026852846401718644,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.8571428571428571,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 19,\n",
       "          'gain': 0.011172668513388773},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.9259259259259259,\n",
       "         'level': 8,\n",
       "         'split': [1, 34873.818181818184],\n",
       "         'n_samples': 25,\n",
       "         'gain': 0.02346666666666665,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.9583333333333334,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 22,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.6,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0.4444444444444444}}}}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.6804878048780488,\n",
       "      'level': 5,\n",
       "      'split': [5, 1.0],\n",
       "      'n_samples': 408,\n",
       "      'gain': 0.012729210678948388,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.7303754266211604,\n",
       "       'level': 6,\n",
       "       'split': [7, 1.0],\n",
       "       'n_samples': 291,\n",
       "       'gain': 0.014976047565620876,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.875,\n",
       "        'level': 7,\n",
       "        'split': [1, 40661.36363636363],\n",
       "        'n_samples': 70,\n",
       "        'gain': 0.007194234337091376,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.7857142857142857,\n",
       "         'level': 8,\n",
       "         'split': [1, 36185.90909090909],\n",
       "         'n_samples': 26,\n",
       "         'gain': 0.02054099746407423,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5714285714285714,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.21333333333333332},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.8260869565217391,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 21,\n",
       "          'gain': 0.04489795918367351}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.9130434782608695,\n",
       "         'level': 8,\n",
       "         'split': [1, 50089.545454545456],\n",
       "         'n_samples': 44,\n",
       "         'gain': 0.006611570247934073,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.9285714285714286,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 40,\n",
       "          'gain': 0.004090909090908992},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.6666666666666666,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0.125}}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.6816143497757847,\n",
       "        'level': 7,\n",
       "        'split': [1, 45271.0],\n",
       "        'n_samples': 221,\n",
       "        'gain': 0.007097876213305154,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.7253521126760564,\n",
       "         'level': 8,\n",
       "         'split': [1, 38837.818181818184],\n",
       "         'n_samples': 140,\n",
       "         'gain': 0.0054138694951665345,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.6666666666666666,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 64,\n",
       "          'gain': 0.012031750801282048},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7692307692307693,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 76,\n",
       "          'gain': 0.004988847717379508}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.6024096385542169,\n",
       "         'level': 8,\n",
       "         'split': [1, 45537.18181818182],\n",
       "         'n_samples': 81,\n",
       "         'gain': 0.011588297807926862,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.4,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 8,\n",
       "          'gain': 0.16875},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.6266666666666667,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 73,\n",
       "          'gain': 0.01093095932653082}}}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.5546218487394958,\n",
       "       'level': 6,\n",
       "       'split': [1, 47695.27272727273],\n",
       "       'n_samples': 117,\n",
       "       'gain': 0.009935613444385316,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.5876288659793815,\n",
       "        'level': 7,\n",
       "        'split': [1, 40562.0],\n",
       "        'n_samples': 95,\n",
       "        'gain': 0.004928567535022466,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.6296296296296297,\n",
       "         'level': 8,\n",
       "         'split': [1, 39788.545454545456],\n",
       "         'n_samples': 52,\n",
       "         'gain': 0.013024795717103466,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5909090909090909,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 42,\n",
       "          'gain': 0.03449098937820749},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.75,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 10,\n",
       "          'gain': 0.14222222222222206}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5333333333333333,\n",
       "         'level': 8,\n",
       "         'split': [1, 42113.36363636363],\n",
       "         'n_samples': 43,\n",
       "         'gain': 0.03144972289584025,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.35714285714285715,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 12,\n",
       "          'gain': 0.07407407407407407},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.6060606060606061,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 31,\n",
       "          'gain': 0.02224114190815546}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.4166666666666667,\n",
       "        'level': 7,\n",
       "        'split': [1, 49454.09090909091],\n",
       "        'n_samples': 22,\n",
       "        'gain': 0.05327626918536016,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.6,\n",
       "         'level': 8,\n",
       "         'split': [1, 48283.454545454544],\n",
       "         'n_samples': 8,\n",
       "         'gain': 0.28125,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.3333333333333333,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0.375},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.8333333333333334,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.3125,\n",
       "         'level': 8,\n",
       "         'split': [1, 49961.545454545456],\n",
       "         'n_samples': 14,\n",
       "         'gain': 0.04452690166975881,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.2,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.38461538461538464,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 11,\n",
       "          'gain': 0.08099173553719008}}}}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 0.5303030303030303,\n",
       "     'level': 4,\n",
       "     'split': [1, 23655.636363636357],\n",
       "     'n_samples': 328,\n",
       "     'gain': 0.05955840000088869,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.8043478260869565,\n",
       "      'level': 5,\n",
       "      'split': [1, 21932.81818181818],\n",
       "      'n_samples': 90,\n",
       "      'gain': 0.014513031550068334,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.8313253012048193,\n",
       "       'level': 6,\n",
       "       'split': [1, 9236.363636363636],\n",
       "       'n_samples': 81,\n",
       "       'gain': 0.005645647902821405,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.9,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 8,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.8133333333333334,\n",
       "        'level': 7,\n",
       "        'split': [1, 18452.545454545456],\n",
       "        'n_samples': 73,\n",
       "        'gain': 0.005265147497559353,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.7708333333333334,\n",
       "         'level': 8,\n",
       "         'split': [1, 17835.36363636364],\n",
       "         'n_samples': 46,\n",
       "         'gain': 0.03570473511918476,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.813953488372093,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 41,\n",
       "          'gain': 0.010619442029317083},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.42857142857142855,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.21333333333333332}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8620689655172413,\n",
       "         'level': 8,\n",
       "         'split': [1, 19867.363636363636],\n",
       "         'n_samples': 27,\n",
       "         'gain': 0.019753086419753152,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.9285714285714286,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 12,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7647058823529411,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 15,\n",
       "          'gain': 0.029090909090908945}}}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.5454545454545454,\n",
       "       'level': 6,\n",
       "       'split': [1, 22447.63636363636],\n",
       "       'n_samples': 9,\n",
       "       'gain': 0.49382716049382713,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.8571428571428571,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 5,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.16666666666666666,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 4,\n",
       "        'gain': 0}}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.425,\n",
       "      'level': 5,\n",
       "      'split': [1, 38799.454545454544],\n",
       "      'n_samples': 238,\n",
       "      'gain': 0.0254138300807476,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.5098039215686274,\n",
       "       'level': 6,\n",
       "       'split': [1, 25223.272727272728],\n",
       "       'n_samples': 151,\n",
       "       'gain': 0.0036111051785545634,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.625,\n",
       "        'level': 7,\n",
       "        'split': [1, 24999.272727272728],\n",
       "        'n_samples': 14,\n",
       "        'gain': 0.10204081632653056,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': [1, 24602.63636363636],\n",
       "         'n_samples': 10,\n",
       "         'gain': 0.2142857142857143,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.6666666666666666,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 7,\n",
       "          'gain': 0.12244897959183676},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.2,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8333333333333334,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 4,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.49640287769784175,\n",
       "        'level': 7,\n",
       "        'split': [1, 26612.363636363636],\n",
       "        'n_samples': 137,\n",
       "        'gain': 0.007462809894410449,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.3333333333333333,\n",
       "         'level': 8,\n",
       "         'split': [1, 25878.636363636364],\n",
       "         'n_samples': 13,\n",
       "         'gain': 0.10680473372781069,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5714285714285714,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.21333333333333332},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.2,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 8,\n",
       "          'gain': 0.09375}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5158730158730159,\n",
       "         'level': 8,\n",
       "         'split': [1, 28249.0],\n",
       "         'n_samples': 124,\n",
       "         'gain': 0.004856052722858162,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.6428571428571429,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 12,\n",
       "          'gain': 0.05555555555555558},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 112,\n",
       "          'gain': 0.0023547880690737433}}}},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.2808988764044944,\n",
       "       'level': 6,\n",
       "       'split': [1, 49465.90909090909],\n",
       "       'n_samples': 87,\n",
       "       'gain': 0.0205175763259699,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.3287671232876712,\n",
       "        'level': 7,\n",
       "        'split': [1, 46734.36363636363],\n",
       "        'n_samples': 71,\n",
       "        'gain': 0.008486906044177789,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.3,\n",
       "         'level': 8,\n",
       "         'split': [1, 42513.0],\n",
       "         'n_samples': 58,\n",
       "         'gain': 0.0063140263422665766,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.35294117647058826,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 32,\n",
       "          'gain': 0.024447737068965525},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.25,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 26,\n",
       "          'gain': 0.02535925612848694}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.4666666666666667,\n",
       "         'level': 8,\n",
       "         'split': [1, 47787.72727272727],\n",
       "         'n_samples': 13,\n",
       "         'gain': 0.028176951253874316,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5555555555555556,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 7,\n",
       "          'gain': 0.08503401360544216},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.375,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0.2222222222222222}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.1111111111111111,\n",
       "        'level': 7,\n",
       "        'split': [1, 51635.272727272735],\n",
       "        'n_samples': 16,\n",
       "        'gain': 0.0546875,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.0625,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 14,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': [1, 51701.27272727273],\n",
       "         'n_samples': 2,\n",
       "         'gain': 0.5,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0}}}}}}},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.9278323162642611,\n",
       "    'level': 3,\n",
       "    'split': [1, 30771.999999999993],\n",
       "    'n_samples': 3767,\n",
       "    'gain': 0.008300801773423822,\n",
       "    'sl': {'y_pred': 1,\n",
       "     'y_prob': 0.986387943607195,\n",
       "     'level': 4,\n",
       "     'split': -1,\n",
       "     'n_samples': 2055,\n",
       "     'gain': 0.00023956749233127253},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 0.8570595099183197,\n",
       "     'level': 4,\n",
       "     'split': [6, 1.0],\n",
       "     'n_samples': 1712,\n",
       "     'gain': 0.005854000731995768,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.8903225806451613,\n",
       "      'level': 5,\n",
       "      'split': [1, 41462.0],\n",
       "      'n_samples': 1238,\n",
       "      'gain': 0.005257436508304791,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.9364844903988183,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 675,\n",
       "       'gain': 0.0007475092944776995},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.8336283185840708,\n",
       "       'level': 6,\n",
       "       'split': [1, 46702.63636363637],\n",
       "       'n_samples': 563,\n",
       "       'gain': 0.003379958748983003,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.8638888888888889,\n",
       "        'level': 7,\n",
       "        'split': [1, 42784.36363636363],\n",
       "        'n_samples': 358,\n",
       "        'gain': 0.0026957243802177566,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.8,\n",
       "         'level': 8,\n",
       "         'split': [1, 42560.181818181816],\n",
       "         'n_samples': 98,\n",
       "         'gain': 0.00860983849322039,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.7682926829268293,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 80,\n",
       "          'gain': 0.012133838383838358},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.9,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 18,\n",
       "          'gain': 0.04938271604938274}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8854961832061069,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 260,\n",
       "         'gain': 0.0005647740231283227}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.7777777777777778,\n",
       "        'level': 7,\n",
       "        'split': [1, 48359.54545454545],\n",
       "        'n_samples': 205,\n",
       "        'gain': 0.008764502204121505,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.6883116883116883,\n",
       "         'level': 8,\n",
       "         'split': [1, 47469.09090909091],\n",
       "         'n_samples': 75,\n",
       "         'gain': 0.00844865295711783,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.75,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 34,\n",
       "          'gain': 0.06854506508485742},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.627906976744186,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 41,\n",
       "          'gain': 0.03256088547581715}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8257575757575758,\n",
       "         'level': 8,\n",
       "         'split': [1, 50416.27272727273],\n",
       "         'n_samples': 130,\n",
       "         'gain': 0.0076979296297290944,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.8767123287671232,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 71,\n",
       "          'gain': 0.020834287051307354},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7540983606557377,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 59,\n",
       "          'gain': 0.01562660913964209}}}}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.7689075630252101,\n",
       "      'level': 5,\n",
       "      'split': [1, 46073.0],\n",
       "      'n_samples': 474,\n",
       "      'gain': 0.010029135590344795,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.8020565552699229,\n",
       "       'level': 6,\n",
       "       'split': [0, 2016.0],\n",
       "       'n_samples': 387,\n",
       "       'gain': 0.0012831704818612177,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.7659574468085106,\n",
       "        'level': 7,\n",
       "        'split': [1, 39320.27272727273],\n",
       "        'n_samples': 139,\n",
       "        'gain': 0.004733081153282415,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.8,\n",
       "         'level': 8,\n",
       "         'split': [1, 35513.90909090909],\n",
       "         'n_samples': 88,\n",
       "         'gain': 0.001558810507674202,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.7758620689655172,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 56,\n",
       "          'gain': 0.009003601440576325},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.8235294117647058,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 32,\n",
       "          'gain': 0.04308363970588239}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.6981132075471698,\n",
       "         'level': 8,\n",
       "         'split': [1, 43124.63636363637],\n",
       "         'n_samples': 51,\n",
       "         'gain': 0.023737883900363077,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.6,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 28,\n",
       "          'gain': 0.03704081632653056},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.8,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 23,\n",
       "          'gain': 0.02646502835538761}}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.82,\n",
       "        'level': 7,\n",
       "        'split': [1, 32995.72727272727],\n",
       "        'n_samples': 248,\n",
       "        'gain': 0.001423738356281512,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.72,\n",
       "         'level': 8,\n",
       "         'split': [1, 32104.0],\n",
       "         'n_samples': 23,\n",
       "         'gain': 0.08749662435862826,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5625,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 14,\n",
       "          'gain': 0.2612244897959185},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.9090909090909091,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 9,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8281938325991189,\n",
       "         'level': 8,\n",
       "         'split': [1, 40315.181818181816],\n",
       "         'n_samples': 225,\n",
       "         'gain': 0.0016597127017021762,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.8557692307692307,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 102,\n",
       "          'gain': 0.0035924132809945497},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.8,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 123,\n",
       "          'gain': 0.007487753371238581}}}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.6179775280898876,\n",
       "       'level': 6,\n",
       "       'split': [1, 47244.09090909091],\n",
       "       'n_samples': 87,\n",
       "       'gain': 0.00753629984424975,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.7222222222222222,\n",
       "        'level': 7,\n",
       "        'split': [1, 47103.81818181818],\n",
       "        'n_samples': 16,\n",
       "        'gain': 0.01785714285714285,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.6875,\n",
       "         'level': 8,\n",
       "         'split': [1, 46122.090909090904],\n",
       "         'n_samples': 14,\n",
       "         'gain': 0.015306122448979664,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7142857142857143,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 12,\n",
       "          'gain': 0.041666666666666685}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.75,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 2,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.589041095890411,\n",
       "        'level': 7,\n",
       "        'split': [1, 49158.454545454544],\n",
       "        'n_samples': 71,\n",
       "        'gain': 0.015108164334508345,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.5121951219512195,\n",
       "         'level': 8,\n",
       "         'split': [1, 48802.72727272727],\n",
       "         'n_samples': 39,\n",
       "         'gain': 0.022565041795811036,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5588235294117647,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 32,\n",
       "          'gain': 0.010865660919540165},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.3333333333333333,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 7,\n",
       "          'gain': 0.217687074829932}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.6764705882352942,\n",
       "         'level': 8,\n",
       "         'split': [1, 50674.63636363636],\n",
       "         'n_samples': 32,\n",
       "         'gain': 0.0421875000000001,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.7727272727272727,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 20,\n",
       "          'gain': 0.02909090909090889},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 12,\n",
       "          'gain': 0.04545454545454547}}}}}}}}},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12133499688084841,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 3204,\n",
       "  'gain': 0.04366470703709979,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.03787566899958831,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 2427,\n",
       "   'gain': 0.0044807442426036265,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.007571345369831101,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1715,\n",
       "    'gain': 6.140801902596027e-05},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.11204481792717087,\n",
       "    'level': 3,\n",
       "    'split': [1, 71316.81818181818],\n",
       "    'n_samples': 712,\n",
       "    'gain': 0.008448612165673108,\n",
       "    'sl': {'y_pred': 0,\n",
       "     'y_prob': 0.19923371647509577,\n",
       "     'level': 4,\n",
       "     'split': [2, 1.0],\n",
       "     'n_samples': 259,\n",
       "     'gain': 0.04528745451218574,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.14655172413793102,\n",
       "      'level': 5,\n",
       "      'split': [1, 59493.45454545455],\n",
       "      'n_samples': 230,\n",
       "      'gain': 0.002541639075808011,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.19767441860465115,\n",
       "       'level': 6,\n",
       "       'split': [1, 57204.63636363636],\n",
       "       'n_samples': 84,\n",
       "       'gain': 0.020415063976493508,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.12727272727272726,\n",
       "        'level': 7,\n",
       "        'split': [8, 1.0],\n",
       "        'n_samples': 53,\n",
       "        'gain': 0.009056957560989592,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.10416666666666667,\n",
       "         'level': 8,\n",
       "         'split': [7, 0.6363636363636367],\n",
       "         'n_samples': 46,\n",
       "         'gain': 0.009394279842176168,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.06451612903225806,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 29,\n",
       "          'gain': 0.006242568370986759},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.21052631578947367,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 17,\n",
       "          'gain': 0.04163783160322945}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.3333333333333333,\n",
       "         'level': 8,\n",
       "         'split': [1, 52759.36363636364],\n",
       "         'n_samples': 7,\n",
       "         'gain': 0.0653061224489796,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.25,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.42857142857142855,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.17999999999999994}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.3333333333333333,\n",
       "        'level': 7,\n",
       "        'split': [5, 0.2727272727272734],\n",
       "        'n_samples': 31,\n",
       "        'gain': 0.0983350676378772,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.26666666666666666,\n",
       "         'level': 8,\n",
       "         'split': [8, 1.0],\n",
       "         'n_samples': 28,\n",
       "         'gain': 0.02083333333333326,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.23076923076923078,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 24,\n",
       "          'gain': 0.0187500000000001},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0.5}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 3,\n",
       "         'gain': 0}}},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.12162162162162163,\n",
       "       'level': 6,\n",
       "       'split': [1, 62401.18181818182],\n",
       "       'n_samples': 146,\n",
       "       'gain': 0.003331362392321263,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.07142857142857142,\n",
       "        'level': 7,\n",
       "        'split': [7, 1.0],\n",
       "        'n_samples': 40,\n",
       "        'gain': 0.010384615384615464,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.034482758620689655,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 27,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.2,\n",
       "         'level': 8,\n",
       "         'split': [1, 60377.36363636363],\n",
       "         'n_samples': 13,\n",
       "         'gain': 0.10650887573964496,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0.5},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.09090909090909091,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 9,\n",
       "          'gain': 0}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.14814814814814814,\n",
       "        'level': 7,\n",
       "        'split': [1, 64315.72727272728],\n",
       "        'n_samples': 106,\n",
       "        'gain': 0.0075128772480879125,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.25806451612903225,\n",
       "         'level': 8,\n",
       "         'split': [7, 1.0],\n",
       "         'n_samples': 29,\n",
       "         'gain': 0.0524375743162902,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.36363636363636365,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 20,\n",
       "          'gain': 0.04620879120879123},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.09090909090909091,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 9,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.11392405063291139,\n",
       "         'level': 8,\n",
       "         'split': [1, 70188.0],\n",
       "         'n_samples': 77,\n",
       "         'gain': 0.005415940480875625,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.09230769230769231,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 63,\n",
       "          'gain': 0.00609725371630121},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.25,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 14,\n",
       "          'gain': 0.06887755102040821}}}}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.6129032258064516,\n",
       "      'level': 5,\n",
       "      'split': [1, 65657.90909090909],\n",
       "      'n_samples': 29,\n",
       "      'gain': 0.033738094380187045,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.7,\n",
       "       'level': 6,\n",
       "       'split': [1, 55890.454545454544],\n",
       "       'n_samples': 18,\n",
       "       'gain': 0.05935422602089274,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.8571428571428571,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 5,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.6,\n",
       "        'level': 7,\n",
       "        'split': [1, 56238.09090909091],\n",
       "        'n_samples': 13,\n",
       "        'gain': 0.13770844540075305,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.25,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 2,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.6923076923076923,\n",
       "         'level': 8,\n",
       "         'split': [1, 61251.545454545456],\n",
       "         'n_samples': 11,\n",
       "         'gain': 0.08500590318772139,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5555555555555556,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 7,\n",
       "          'gain': 0.2612244897959185},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.8333333333333334,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0}}}},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.46153846153846156,\n",
       "       'level': 6,\n",
       "       'split': [1, 66811.45454545454],\n",
       "       'n_samples': 11,\n",
       "       'gain': 0.23612750885478173,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.16666666666666666,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 4,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.6666666666666666,\n",
       "        'level': 7,\n",
       "        'split': [1, 68945.0],\n",
       "        'n_samples': 7,\n",
       "        'gain': 0.12244897959183676,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': [1, 66998.54545454546],\n",
       "         'n_samples': 4,\n",
       "         'gain': 0.16666666666666669,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.4,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0.1111111111111111}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 3,\n",
       "         'gain': 0}}}}},\n",
       "    'sr': {'y_pred': 0,\n",
       "     'y_prob': 0.06373626373626373,\n",
       "     'level': 4,\n",
       "     'split': [1, 92189.63636363635],\n",
       "     'n_samples': 453,\n",
       "     'gain': 0.0028290521843437333,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.09310344827586207,\n",
       "      'level': 5,\n",
       "      'split': [7, 1.0],\n",
       "      'n_samples': 288,\n",
       "      'gain': 0.0022297392089057344,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.07589285714285714,\n",
       "       'level': 6,\n",
       "       'split': [2, 0.9090909090909349],\n",
       "       'n_samples': 222,\n",
       "       'gain': 0.0029294551279225867,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.06403940886699508,\n",
       "        'level': 7,\n",
       "        'split': [8, 1.0],\n",
       "        'n_samples': 201,\n",
       "        'gain': 0.0016147294965599968,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.05263157894736842,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 169,\n",
       "         'gain': 0.00082021484891448},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.14705882352941177,\n",
       "         'level': 8,\n",
       "         'split': [1, 83719.72727272728],\n",
       "         'n_samples': 32,\n",
       "         'gain': 0.0187500000000001,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.22727272727272727,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 20,\n",
       "          'gain': 0.02909090909090889},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.07142857142857142,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 12,\n",
       "          'gain': 0}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.21739130434782608,\n",
       "        'level': 7,\n",
       "        'split': [0, 2013.0],\n",
       "        'n_samples': 21,\n",
       "        'gain': 0.07558578987150422,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.15,\n",
       "         'level': 8,\n",
       "         'split': [1, 77213.45454545454],\n",
       "         'n_samples': 18,\n",
       "         'gain': 0.08641975308641975,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0.16666666666666669},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.0625,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 14,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.6,\n",
       "         'level': 8,\n",
       "         'split': [1, 78647.63636363635],\n",
       "         'n_samples': 3,\n",
       "         'gain': 0.4444444444444444,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.75,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0}}}},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.16176470588235295,\n",
       "       'level': 6,\n",
       "       'split': [1, 73476.81818181819],\n",
       "       'n_samples': 66,\n",
       "       'gain': 0.006611570247933796,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.375,\n",
       "        'level': 7,\n",
       "        'split': [1, 71352.36363636363],\n",
       "        'n_samples': 6,\n",
       "        'gain': 0.17777777777777787,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 1,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.2857142857142857,\n",
       "         'level': 8,\n",
       "         'split': [1, 71959.90909090909],\n",
       "         'n_samples': 5,\n",
       "         'gain': 0.11999999999999983,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.2,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.14516129032258066,\n",
       "        'level': 7,\n",
       "        'split': [1, 89709.0],\n",
       "        'n_samples': 60,\n",
       "        'gain': 0.008888888888888807,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.125,\n",
       "         'level': 8,\n",
       "         'split': [1, 77046.0],\n",
       "         'n_samples': 54,\n",
       "         'gain': 0.0035914702581368585,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.25,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 10,\n",
       "          'gain': 0.14222222222222206},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.10869565217391304,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 44,\n",
       "          'gain': 0.011248852157943162}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.375,\n",
       "         'level': 8,\n",
       "         'split': [1, 91349.54545454546],\n",
       "         'n_samples': 6,\n",
       "         'gain': 0.17777777777777787,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.2857142857142857,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.11999999999999983},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0}}}}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.017964071856287425,\n",
       "      'level': 5,\n",
       "      'split': -1,\n",
       "      'n_samples': 165,\n",
       "      'gain': 0.0005950413223138745}}}},\n",
       "  'sr': {'y_pred': 0,\n",
       "   'y_prob': 0.38254172015404364,\n",
       "   'level': 2,\n",
       "   'split': [1, 69702.90909090909],\n",
       "   'n_samples': 777,\n",
       "   'gain': 0.040449309391888344,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.4899193548387097,\n",
       "    'level': 3,\n",
       "    'split': [8, 1.0],\n",
       "    'n_samples': 494,\n",
       "    'gain': 0.024087071241494562,\n",
       "    'sl': {'y_pred': 0,\n",
       "     'y_prob': 0.4444444444444444,\n",
       "     'level': 4,\n",
       "     'split': [0, 2016.0],\n",
       "     'n_samples': 421,\n",
       "     'gain': 0.028321955781708874,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.40053763440860213,\n",
       "      'level': 5,\n",
       "      'split': [0, 2015.0],\n",
       "      'n_samples': 370,\n",
       "      'gain': 0.01229597107438013,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.3442622950819672,\n",
       "       'level': 6,\n",
       "       'split': [1, 61572.27272727272],\n",
       "       'n_samples': 242,\n",
       "       'gain': 0.003962697708002061,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.3782051282051282,\n",
       "        'level': 7,\n",
       "        'split': [1, 59028.181818181816],\n",
       "        'n_samples': 154,\n",
       "        'gain': 0.011248852157943023,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.34375,\n",
       "         'level': 8,\n",
       "         'split': [5, 0.9090909090909065],\n",
       "         'n_samples': 126,\n",
       "         'gain': 0.0153516677326202,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.3978494623655914,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 91,\n",
       "          'gain': 0.02229317185093105},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.21621621621621623,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 35,\n",
       "          'gain': 0.010322580645161117}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5333333333333333,\n",
       "         'level': 8,\n",
       "         'split': [5, 1.0],\n",
       "         'n_samples': 28,\n",
       "         'gain': 0.11757884972170685,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.4166666666666667,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 22,\n",
       "          'gain': 0.05165289256198352},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.875,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.28888888888888886,\n",
       "        'level': 7,\n",
       "        'split': [1, 67976.81818181818],\n",
       "        'n_samples': 88,\n",
       "        'gain': 0.02071854912764004,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.24324324324324326,\n",
       "         'level': 8,\n",
       "         'split': [1, 67144.09090909091],\n",
       "         'n_samples': 72,\n",
       "         'gain': 0.0022579755983711536,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.22950819672131148,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 59,\n",
       "          'gain': 0.007678044449087262},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.3333333333333333,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 13,\n",
       "          'gain': 0.06339814032121738}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': [5, 0.6363636363636367],\n",
       "         'n_samples': 16,\n",
       "         'gain': 0.07142857142857145,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5625,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 14,\n",
       "          'gain': 0.06122448979591838},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.25,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0}}}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.5076923076923077,\n",
       "       'level': 6,\n",
       "       'split': [1, 56263.27272727272],\n",
       "       'n_samples': 128,\n",
       "       'gain': 0.041582998811923955,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.7297297297297297,\n",
       "        'level': 7,\n",
       "        'split': [1, 52976.27272727273],\n",
       "        'n_samples': 35,\n",
       "        'gain': 0.015220539828834645,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': [1, 52675.18181818182],\n",
       "         'n_samples': 4,\n",
       "         'gain': 0.5,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.25,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.75,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.7575757575757576,\n",
       "         'level': 8,\n",
       "         'split': [1, 53610.0],\n",
       "         'n_samples': 31,\n",
       "         'gain': 0.02447450572320503,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.875,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.7037037037037037,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 25,\n",
       "          'gain': 0.017168253968254}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.42105263157894735,\n",
       "        'level': 7,\n",
       "        'split': [2, 0.6363636363636402],\n",
       "        'n_samples': 93,\n",
       "        'gain': 0.07224617214211387,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.36046511627906974,\n",
       "         'level': 8,\n",
       "         'split': [1, 61913.454545454544],\n",
       "         'n_samples': 84,\n",
       "         'gain': 0.02391070844813903,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.4583333333333333,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 46,\n",
       "          'gain': 0.028774955046337036},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.25,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 38,\n",
       "          'gain': 0.05055720796047858}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.9090909090909091,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 9,\n",
       "         'gain': 0}}}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.7547169811320755,\n",
       "      'level': 5,\n",
       "      'split': [6, 0.2727272727272698],\n",
       "      'n_samples': 51,\n",
       "      'gain': 0.06537858109995909,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.9,\n",
       "       'level': 6,\n",
       "       'split': [1, 54485.454545454544],\n",
       "       'n_samples': 28,\n",
       "       'gain': 0.011773940345368952,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.8,\n",
       "        'level': 7,\n",
       "        'split': [1, 54390.18181818182],\n",
       "        'n_samples': 13,\n",
       "        'gain': 0.04357181280258193,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.8461538461538461,\n",
       "         'level': 8,\n",
       "         'split': [1, 52671.0],\n",
       "         'n_samples': 11,\n",
       "         'gain': 0.01983471074380186,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.7142857142857143,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.31999999999999984},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.875,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': [1, 54418.454545454544],\n",
       "         'n_samples': 2,\n",
       "         'gain': 0.5,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0}}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.9411764705882353,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 15,\n",
       "        'gain': 0}},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.56,\n",
       "       'level': 6,\n",
       "       'split': [1, 54268.0],\n",
       "       'n_samples': 23,\n",
       "       'gain': 0.027948233241238962,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.6666666666666666,\n",
       "        'level': 7,\n",
       "        'split': [1, 52786.18181818182],\n",
       "        'n_samples': 10,\n",
       "        'gain': 0.11523809523809525,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.4,\n",
       "         'level': 8,\n",
       "         'split': [1, 52404.727272727265],\n",
       "         'n_samples': 3,\n",
       "         'gain': 0.1111111111111111,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.7777777777777778,\n",
       "         'level': 8,\n",
       "         'split': [1, 53600.0],\n",
       "         'n_samples': 7,\n",
       "         'gain': 0.030612244897959245,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.8,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.6666666666666666,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0.375}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.4666666666666667,\n",
       "        'level': 7,\n",
       "        'split': [1, 54608.36363636363],\n",
       "        'n_samples': 13,\n",
       "        'gain': 0.025246548323471396,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.6,\n",
       "         'level': 8,\n",
       "         'split': [1, 54324.181818181816],\n",
       "         'n_samples': 3,\n",
       "         'gain': 0.4444444444444444,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.75,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.4166666666666667,\n",
       "         'level': 8,\n",
       "         'split': [1, 62008.63636363636],\n",
       "         'n_samples': 10,\n",
       "         'gain': 0.08000000000000007,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.2857142857142857,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.11999999999999983},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5714285714285714,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 5,\n",
       "          'gain': 0.07999999999999996}}}}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 0.7466666666666667,\n",
       "     'level': 4,\n",
       "     'split': [1, 60252.454545454544],\n",
       "     'n_samples': 73,\n",
       "     'gain': 0.014910125840882194,\n",
       "     'sl': {'y_pred': 1,\n",
       "      'y_prob': 0.8285714285714286,\n",
       "      'level': 5,\n",
       "      'split': [1, 54833.63636363637],\n",
       "      'n_samples': 33,\n",
       "      'gain': 0.017217630853994303,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.9090909090909091,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 9,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.7692307692307693,\n",
       "       'level': 6,\n",
       "       'split': [1, 58459.0],\n",
       "       'n_samples': 24,\n",
       "       'gain': 0.023334304584304577,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.6666666666666666,\n",
       "        'level': 7,\n",
       "        'split': [1, 57444.72727272728],\n",
       "        'n_samples': 13,\n",
       "        'gain': 0.07731755424063136,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.75,\n",
       "         'level': 8,\n",
       "         'split': [0, 2015.181818181818],\n",
       "         'n_samples': 10,\n",
       "         'gain': 0.14222222222222206,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.8181818181818182,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 9,\n",
       "          'gain': 0.04938271604938271},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.4,\n",
       "         'level': 8,\n",
       "         'split': [0, 2014.181818181818],\n",
       "         'n_samples': 3,\n",
       "         'gain': 0.1111111111111111,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5}}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.8461538461538461,\n",
       "        'level': 7,\n",
       "        'split': [1, 59983.454545454544],\n",
       "        'n_samples': 11,\n",
       "        'gain': 0.02892561983471087,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.8888888888888888,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 7,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.6666666666666666,\n",
       "         'level': 8,\n",
       "         'split': [1, 60024.90909090909],\n",
       "         'n_samples': 4,\n",
       "         'gain': 0.375,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.8,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0}}}}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.6666666666666666,\n",
       "      'level': 5,\n",
       "      'split': [1, 60534.09090909091],\n",
       "      'n_samples': 40,\n",
       "      'gain': 0.023472222222222117,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.8333333333333334,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 4,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.631578947368421,\n",
       "       'level': 6,\n",
       "       'split': [1, 61148.27272727273],\n",
       "       'n_samples': 36,\n",
       "       'gain': 0.0378086419753087,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.3333333333333333,\n",
       "        'level': 7,\n",
       "        'split': [1, 60601.818181818184],\n",
       "        'n_samples': 4,\n",
       "        'gain': 0.375,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 1,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.2,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 3,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.6764705882352942,\n",
       "        'level': 7,\n",
       "        'split': [1, 69162.27272727272],\n",
       "        'n_samples': 32,\n",
       "        'gain': 0.02020474137931033,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.6451612903225806,\n",
       "         'level': 8,\n",
       "         'split': [1, 68541.0],\n",
       "         'n_samples': 29,\n",
       "         'gain': 0.023903167779505408,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.6785714285714286,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 26,\n",
       "          'gain': 0.02035784728092427},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.4,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0.4444444444444444}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.8,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 3,\n",
       "         'gain': 0}}}}}},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.19649122807017544,\n",
       "    'level': 3,\n",
       "    'split': [8, 1.0],\n",
       "    'n_samples': 283,\n",
       "    'gain': 0.025513433574225197,\n",
       "    'sl': {'y_pred': 0,\n",
       "     'y_prob': 0.1553784860557769,\n",
       "     'level': 4,\n",
       "     'split': [1, 89691.81818181818],\n",
       "     'n_samples': 249,\n",
       "     'gain': 0.008844272731990593,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.19672131147540983,\n",
       "      'level': 5,\n",
       "      'split': [6, 1.0],\n",
       "      'n_samples': 181,\n",
       "      'gain': 0.010066764731326172,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.23741007194244604,\n",
       "       'level': 6,\n",
       "       'split': [1, 70619.18181818182],\n",
       "       'n_samples': 137,\n",
       "       'gain': 0.010896220696526182,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.4666666666666667,\n",
       "        'level': 7,\n",
       "        'split': [1, 70166.18181818182],\n",
       "        'n_samples': 13,\n",
       "        'gain': 0.1490560721329952,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.6666666666666666,\n",
       "         'level': 8,\n",
       "         'split': [0, 2015.4545454545455],\n",
       "         'n_samples': 7,\n",
       "         'gain': 0.17006802721088446,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.75,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0.2777777777777777},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.25,\n",
       "         'level': 8,\n",
       "         'split': [0, 2014.1818181818182],\n",
       "         'n_samples': 6,\n",
       "         'gain': 0.11111111111111102,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.16666666666666666,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 4,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.21428571428571427,\n",
       "        'level': 7,\n",
       "        'split': [0, 2015.0],\n",
       "        'n_samples': 124,\n",
       "        'gain': 0.0072848533273870975,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.1836734693877551,\n",
       "         'level': 8,\n",
       "         'split': [1, 73580.18181818182],\n",
       "         'n_samples': 96,\n",
       "         'gain': 0.006816461894587067,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.1,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 18,\n",
       "          'gain': 0.016049382716049443},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.2125,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 78,\n",
       "          'gain': 0.003715301792224679}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.3333333333333333,\n",
       "         'level': 8,\n",
       "         'split': [2, 1.0],\n",
       "         'n_samples': 28,\n",
       "         'gain': 0.142934446505875,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.20833333333333334,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 22,\n",
       "          'gain': 0.024793388429752206},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.75,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0.2777777777777777}}}},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.08695652173913043,\n",
       "       'level': 6,\n",
       "       'split': [0, 2015.0],\n",
       "       'n_samples': 44,\n",
       "       'gain': 0.008608815426997263,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.05714285714285714,\n",
       "        'level': 7,\n",
       "        'split': [1, 86822.18181818182],\n",
       "        'n_samples': 33,\n",
       "        'gain': 0.018365472910927313,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.03125,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 30,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.4,\n",
       "         'level': 8,\n",
       "         'split': [1, 87186.36363636363],\n",
       "         'n_samples': 3,\n",
       "         'gain': 0.1111111111111111,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5}}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.23076923076923078,\n",
       "        'level': 7,\n",
       "        'split': [1, 70853.54545454546],\n",
       "        'n_samples': 11,\n",
       "        'gain': 0.04499540863177237,\n",
       "        'sl': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': [1, 69889.0],\n",
       "         'n_samples': 2,\n",
       "         'gain': 0.5,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 1,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.18181818181818182,\n",
       "         'level': 8,\n",
       "         'split': [0, 2015.090909090909],\n",
       "         'n_samples': 9,\n",
       "         'gain': 0.04938271604938271,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.125,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 6,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.4,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0.4444444444444444}}}}},\n",
       "     'sr': {'y_pred': 0,\n",
       "      'y_prob': 0.05714285714285714,\n",
       "      'level': 5,\n",
       "      'split': [7, 1.0],\n",
       "      'n_samples': 68,\n",
       "      'gain': 0.0028945967527283234,\n",
       "      'sl': {'y_pred': 0,\n",
       "       'y_prob': 0.03225806451612903,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 29,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.0975609756097561,\n",
       "       'level': 6,\n",
       "       'split': [1, 138311.7272727273],\n",
       "       'n_samples': 39,\n",
       "       'gain': 0.006846999154691336,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.08108108108108109,\n",
       "        'level': 7,\n",
       "        'split': [1, 109143.81818181818],\n",
       "        'n_samples': 35,\n",
       "        'gain': 0.003858998144712314,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.125,\n",
       "         'level': 8,\n",
       "         'split': [1, 104141.81818181819],\n",
       "         'n_samples': 22,\n",
       "         'gain': 0.03347107438016533,\n",
       "         'sl': {'y_pred': 0,\n",
       "          'y_prob': 0.09090909090909091,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 20,\n",
       "          'gain': 0.011666666666666783},\n",
       "         'sr': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5}},\n",
       "        'sr': {'y_pred': 0,\n",
       "         'y_prob': 0.06666666666666667,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 13,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.3333333333333333,\n",
       "        'level': 7,\n",
       "        'split': [1, 178585.2727272727],\n",
       "        'n_samples': 4,\n",
       "        'gain': 0.375,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.2,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 3,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 1,\n",
       "         'gain': 0}}}}},\n",
       "    'sr': {'y_pred': 1,\n",
       "     'y_prob': 0.5,\n",
       "     'level': 4,\n",
       "     'split': [0, 2015.0],\n",
       "     'n_samples': 34,\n",
       "     'gain': 0.10888888888888887,\n",
       "     'sl': {'y_pred': 0,\n",
       "      'y_prob': 0.37037037037037035,\n",
       "      'level': 5,\n",
       "      'split': [1, 90268.45454545456],\n",
       "      'n_samples': 25,\n",
       "      'gain': 0.06968888888888886,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.5,\n",
       "       'level': 6,\n",
       "       'split': [1, 70615.45454545454],\n",
       "       'n_samples': 16,\n",
       "       'gain': 0.07142857142857134,\n",
       "       'sl': {'y_pred': 1,\n",
       "        'y_prob': 0.75,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 2,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.4375,\n",
       "        'level': 7,\n",
       "        'split': [1, 74739.36363636363],\n",
       "        'n_samples': 14,\n",
       "        'gain': 0.05804988662131538,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.2857142857142857,\n",
       "         'level': 8,\n",
       "         'split': [1, 71116.63636363637],\n",
       "         'n_samples': 5,\n",
       "         'gain': 0.11999999999999983,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.5,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0.5},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.2,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 3,\n",
       "          'gain': 0}},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5454545454545454,\n",
       "         'level': 8,\n",
       "         'split': [1, 77630.27272727274],\n",
       "         'n_samples': 9,\n",
       "         'gain': 0.11287477954144609,\n",
       "         'sl': {'y_pred': 1,\n",
       "          'y_prob': 0.75,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 2,\n",
       "          'gain': 0},\n",
       "         'sr': {'y_pred': 0,\n",
       "          'y_prob': 0.4444444444444444,\n",
       "          'level': 9,\n",
       "          'split': -1,\n",
       "          'n_samples': 7,\n",
       "          'gain': 0.06122448979591849}}}},\n",
       "      'sr': {'y_pred': 0,\n",
       "       'y_prob': 0.18181818181818182,\n",
       "       'level': 6,\n",
       "       'split': [1, 97248.18181818182],\n",
       "       'n_samples': 9,\n",
       "       'gain': 0.030864197530864196,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.3333333333333333,\n",
       "        'level': 7,\n",
       "        'split': [1, 93653.27272727272],\n",
       "        'n_samples': 4,\n",
       "        'gain': 0.375,\n",
       "        'sl': {'y_pred': 0,\n",
       "         'y_prob': 0.2,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 3,\n",
       "         'gain': 0},\n",
       "        'sr': {'y_pred': 1,\n",
       "         'y_prob': 0.5,\n",
       "         'level': 8,\n",
       "         'split': -1,\n",
       "         'n_samples': 1,\n",
       "         'gain': 0}},\n",
       "       'sr': {'y_pred': 0,\n",
       "        'y_prob': 0.14285714285714285,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 5,\n",
       "        'gain': 0}}},\n",
       "     'sr': {'y_pred': 1,\n",
       "      'y_prob': 0.8181818181818182,\n",
       "      'level': 5,\n",
       "      'split': [1, 80060.36363636363],\n",
       "      'n_samples': 9,\n",
       "      'gain': 0.04938271604938271,\n",
       "      'sl': {'y_pred': 1,\n",
       "       'y_prob': 0.875,\n",
       "       'level': 6,\n",
       "       'split': -1,\n",
       "       'n_samples': 6,\n",
       "       'gain': 0},\n",
       "      'sr': {'y_pred': 1,\n",
       "       'y_prob': 0.6,\n",
       "       'level': 6,\n",
       "       'split': [1, 81955.27272727272],\n",
       "       'n_samples': 3,\n",
       "       'gain': 0.4444444444444444,\n",
       "       'sl': {'y_pred': 0,\n",
       "        'y_prob': 0.5,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 1,\n",
       "        'gain': 0},\n",
       "       'sr': {'y_pred': 1,\n",
       "        'y_prob': 0.75,\n",
       "        'level': 7,\n",
       "        'split': -1,\n",
       "        'n_samples': 2,\n",
       "        'gain': 0}}}}}}}}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del árbol creado, identificamos que el primer nivel de son las millas del vehiculo y el segundo,  el año del carro. Algo interesante es que estás variables vuelven a aparecer en siguientes niveles, lo que nos permite sospechar que probablemente son variables predictoras de alta importancia para clasificar el costo del carro (bajo/alto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción del Precio del Carro\n",
    "Utilizar el árbol creado para identificar si el precio del carro es bajo o alto, dadas las caracteristicas del carro (eg, año, distancia acumulada (millas), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_dt = tree_predict(X_test, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación de accuracy en el set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_d_tree = np.sum(np.equal(y_test,y_predict_dt))/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728110599078341"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_d_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.2\n",
    "Ensamblar 10 árboles de clasificación manualmente (Utilizando bagging notebook).\n",
    "Evaluar accuracy en el set de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "#Número de muestras que tendremos para crear cada árbol (debe ser del mismo tamaño de la muestra original)\n",
    "n_samples = y_train.shape[0]\n",
    "\n",
    "#número de Arboles\n",
    "n_B = 100\n",
    "\n",
    "# creación de 10 muestras (con remplazo)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grow each tree deep\n",
    "treereg = DecisionTreeClassifier(max_depth=len(X.columns), random_state=123)\n",
    "\n",
    "# DataFrame for storing predicted price from each tree\n",
    "y_pred_b = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train_b = X_train.iloc[samples[i]]\n",
    "    y_train_b = y_train.iloc[samples[i]]\n",
    "    treereg.fit(X_train_b, y_train_b)\n",
    "    y_pred_b.iloc[:,i] = treereg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_b=pd.DataFrame(y_pred_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bagging=np.where(y_pred_b.mean(axis=1)<=0.5,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771889400921659"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred_bagging, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión Ensamblaje: \n",
    "El accuracy para nuestro ensamble de 10 arboles (0.87718) es superior que el accuracy para un solo árbol (0.87281). Esto demuestra el teorema de 'Condorcet's Jury,' donde esperamos que al combinar el resultado de múltiples modelos de predicción (clasificadores de árboles de decisión de una única base (single decision tree)), logremos un modelo con mejor rendimiento (mejor poder de predicción)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.3\n",
    "Comparar el impacto de cambiar el parámetro 'Max_features.'\n",
    "\n",
    "Evaluar accuracy en el set de test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el paquete Sklearn para evaluar el efecto de la variable 'Max_features', es decir, cuantas variables incuiremos en nuestro arbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_range = range(1, len(X_test.columns)+1)\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 5-fold cross-validation with each value of max_features\n",
    "for feature in feature_range:\n",
    "    clf = DecisionTreeClassifier(max_features=feature, random_state=1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(feature_range, accuracy_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la gráfica vemos el efecto de aumentar el número de variables incluidas. Identificamos que el valor que máximiza el accuracy es 3. Que de hecho, cumple con la 'rule of thump' para los arboles de clasificación m=sqr(p) donde m es el número de variables a utilizar en el modelo y p el número de variables que tenemos (en este caso, para los carros).\n",
    "\n",
    "Ahora vamos a probar en un ensamble de 10 arboles si efectivamente el útilizar este valor óptimo nos da un mejor accuracy de nuestro modelo, para ello compararemos el modelo con max_features igual a su valor default vs. el valor de máx features encontrado (3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(321)\n",
    "\n",
    "n_estimators = 10\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "#Muestras bootstrap\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features = None (Valor Default), max_features = n_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=None, max_depth=len(X.columns), random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicción\n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8746543778801843"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=3, max_depth=len(X.columns), random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8806451612903226"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión: \n",
    "La intuición diría que un mejor modelo será aquel que tenga más variables. Sin embargo, fue interesante identificar que no es así. Una posible explicación puede ser el efecto que pueden tener de overfiting de variables y además, que el modelo realmente solo necesita aquellas variables que aporten fuertemente a la predicción.\n",
    "\n",
    "El parámetro 'Máx features' establece el número de variables que se incluiran en los arboles (algo así como las hojas del arbol).  encontramos que efectivamente el accuracy es mejor cuando calibramos nuestro modelo con la variable max_features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.4\n",
    "Ensamblar 10 arboles con Bagging y con 'Max_features'= log(n_features).\n",
    "Evaluar accuracy en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "n_estimators = 10\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "#Muestras bootstrap\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"log2\", max_depth=len(X.columns), random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8806451612903226"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión:\n",
    "El valor del accuracy nos dió igual al que encontramos maximizando para máx features. Es decir, log(n_features) también puede ser una buena aproximación para arboles de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.5\n",
    "Utilizar sklearn para entrenar un modelo de Random Forest.\n",
    "Evaluar el accuracy en el set de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfcl = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380184331797235"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcl.fit(X_train, y_train)\n",
    "y_pred_rf = rfcl.predict(X_test)\n",
    "metrics.accuracy_score(y_pred_rf, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los valores default de Random Forest encontramos que el accuracy es inferior al que obtuvimos con Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.6\n",
    "Encontrar los mejores parámetros para: max_depth, max_features y n_estimators\n",
    "Evaluar el accuracy en el set de test.\n",
    "\n",
    "Evaluate the accuracy on the testing set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profundidad, hojas, del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of values to try for max_depth\n",
    "max_depth_range = range(1, 10)\n",
    "accuracy_scores = []\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    clf = RandomForestClassifier(max_depth=depth, random_state=1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot max_depth (x-axis) versus Accuracy (y-axis)\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificamos que la profundidad del árbol que máximiza el accuracy es 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identificar Número de Árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para Random Forest, primero queremos determinar cual es el número de árboles (n_estimators) que maximiza el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_range = range(1, 50, 1)\n",
    "accuracy_scores = []\n",
    "\n",
    "# muestras por 5-fold cross-validation \n",
    "for estimator in estimator_range:\n",
    "    clf = RandomForestClassifier(n_estimators=estimator, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(estimator_range, accuracy_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificamos que el número de árboles que maximiza el accuracy es 22. Ahora buscaremos el máximo número de variables para crear los arboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of values to try for max_features\n",
    "feature_range = range(1, len(X_test.columns)+1)\n",
    "\n",
    "# list to store the average Accuracy for each value of max_features\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 5-fold cross-validation with each value of max_features\n",
    "for feature in feature_range:\n",
    "    clf = RandomForestClassifier(n_estimators=23, max_features=feature, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(feature_range, accuracy_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la gráfica podemos identificar que debemos utilizar todas las variables (9) que tenemos para los carros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit del Random Forest con los parámetros seleccionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, max_features=9, n_estimators=23, n_jobs=-1,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features=9, n_estimators=20 y max_depth=8\n",
    "clf = RandomForestClassifier(n_estimators=23, max_features=9, max_depth=7, random_state=1, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8790322580645161"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.7\n",
    "Utilizar xgBoost para entrenar un XGBClassifier.\n",
    "\n",
    "Evaluar el accuracy en el set de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=20, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clx = XGBClassifier(random_state=20)\n",
    "clx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8790322580645161"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clx.fit(X_train, y_train)\n",
    "y_pred_xgb = clx.predict(X_test)\n",
    "metrics.accuracy_score(y_pred_xgb, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ajustar un modelo de XGBoost con los parámetros por default, se evidencia que el accuracy es superior al que habiamos obtenido con Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8.8\n",
    "Modificar los parámetros learning rate, gamma, colsample_bytree. Explicar que significa cada parámetro.\n",
    "\n",
    "Evaluate the accuracy on the testing set\n",
    "\n",
    "\n",
    "#### Explicación de los parámetros:\n",
    "\n",
    "Learning rate: El aumento de gradiente implica la creación y la adición de árboles al modelo de forma secuencial. Se crean árboles nuevos para corregir los errores residuales en las predicciones de la secuencia de árboles existente. El efecto es que el modelo puede ajustarse rápidamente y luego sobre-ajustarse al conjunto de datos de entrenamiento.\n",
    "\n",
    "Una técnica para ralentizar el aprendizaje en el modelo de aumento de gradiente es aplicar una tasa de aprendizaje o learning rate para las correcciones de nuevos árboles cuando se agregan al modelo.\n",
    "\n",
    "Gamma: Es un parámetro de regularización, el cual funciona usando información \"de los árboles\". Al ajustar gamma, se agregan nodos a los árboles, esto debería realizarse solo si la ganancia asociada es mayor o igual al costo de complejidad creado por introducir nodos u hojas adicionales, de lo contrario se ve afectada la precisión del modelo.\n",
    "\n",
    "Colsample_bytree: es la proporción de submuestra de columnas al construir cada árbol. El submuestreo ocurre una vez por cada árbol construido. Este parámetro tiene un rango de (0, 1], el valor predeterminado es 1 y especifica la fracción de columnas a las cuales se les hará submuestreo.\n",
    "\n",
    "Para escoger el mejor valor en cada parámetro, se realizará una grilla para cada una y con el uso de la función RandomizedSearchCV de sklearn se iterará en todas las combinaciones posibles para encontrar los mejores valores en terminos de accuracy, como se evidencia a continuación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grilla y calibración de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = XGBClassifier(objective = 'binary:logistic')\n",
    "\n",
    "param_dist = {'colsample_bytree': [0.01, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "              'learning_rate': [0.01, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "              'gamma': [0.01, 0.1, 0.2, 5, 10, 50, 100],\n",
    "             }\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xgb, \n",
    "                         param_distributions = param_dist,\n",
    "                         cv = 5,  \n",
    "                         n_iter = 5, # you want 5 here not 25 if I understand you correctly \n",
    "                         scoring = 'accuracy', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1,\n",
    "                         random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    3.3s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    4.4s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=0,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_e...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.01, 0.1, 0.2,\n",
       "                                                             0.5, 0.8, 1],\n",
       "                                        'gamma': [0.01, 0.1, 0.2, 5, 10, 50,\n",
       "                                                  100],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.2, 0.5,\n",
       "                                                          0.8, 1]},\n",
       "                   random_state=20, scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.8, 'gamma': 10, 'colsample_bytree': 0.01},\n",
       " 0.8827468785471055)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_, clf.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicar mejor parámetros encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=0.01, gamma=10,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.8, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate= 0.8, gamma= 10, colsample_bytree= 0.01)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.59459\tvalidation_0-auc:0.51737\tvalidation_1-aucpr:0.59626\tvalidation_1-auc:0.51474\n",
      "[1]\tvalidation_0-aucpr:0.64850\tvalidation_0-auc:0.64868\tvalidation_1-aucpr:0.64961\tvalidation_1-auc:0.64645\n",
      "[2]\tvalidation_0-aucpr:0.69666\tvalidation_0-auc:0.67604\tvalidation_1-aucpr:0.69707\tvalidation_1-auc:0.67354\n",
      "[3]\tvalidation_0-aucpr:0.70066\tvalidation_0-auc:0.68515\tvalidation_1-aucpr:0.70088\tvalidation_1-auc:0.68236\n",
      "[4]\tvalidation_0-aucpr:0.91194\tvalidation_0-auc:0.90054\tvalidation_1-aucpr:0.91570\tvalidation_1-auc:0.90416\n",
      "[5]\tvalidation_0-aucpr:0.92096\tvalidation_0-auc:0.90549\tvalidation_1-aucpr:0.92458\tvalidation_1-auc:0.90939\n",
      "[6]\tvalidation_0-aucpr:0.92096\tvalidation_0-auc:0.90549\tvalidation_1-aucpr:0.92458\tvalidation_1-auc:0.90939\n",
      "[7]\tvalidation_0-aucpr:0.92096\tvalidation_0-auc:0.90549\tvalidation_1-aucpr:0.92458\tvalidation_1-auc:0.90939\n",
      "[8]\tvalidation_0-aucpr:0.92616\tvalidation_0-auc:0.91127\tvalidation_1-aucpr:0.93187\tvalidation_1-auc:0.91646\n",
      "[9]\tvalidation_0-aucpr:0.92638\tvalidation_0-auc:0.91148\tvalidation_1-aucpr:0.93203\tvalidation_1-auc:0.91663\n",
      "[10]\tvalidation_0-aucpr:0.92638\tvalidation_0-auc:0.91148\tvalidation_1-aucpr:0.93203\tvalidation_1-auc:0.91663\n",
      "[11]\tvalidation_0-aucpr:0.92670\tvalidation_0-auc:0.91314\tvalidation_1-aucpr:0.93436\tvalidation_1-auc:0.92015\n",
      "[12]\tvalidation_0-aucpr:0.92670\tvalidation_0-auc:0.91314\tvalidation_1-aucpr:0.93436\tvalidation_1-auc:0.92015\n",
      "[13]\tvalidation_0-aucpr:0.92670\tvalidation_0-auc:0.91314\tvalidation_1-aucpr:0.93436\tvalidation_1-auc:0.92015\n",
      "[14]\tvalidation_0-aucpr:0.92670\tvalidation_0-auc:0.91314\tvalidation_1-aucpr:0.93436\tvalidation_1-auc:0.92015\n",
      "[15]\tvalidation_0-aucpr:0.92670\tvalidation_0-auc:0.91314\tvalidation_1-aucpr:0.93436\tvalidation_1-auc:0.92015\n",
      "[16]\tvalidation_0-aucpr:0.92670\tvalidation_0-auc:0.91314\tvalidation_1-aucpr:0.93436\tvalidation_1-auc:0.92015\n",
      "[17]\tvalidation_0-aucpr:0.95293\tvalidation_0-auc:0.94149\tvalidation_1-aucpr:0.95436\tvalidation_1-auc:0.94246\n",
      "[18]\tvalidation_0-aucpr:0.95293\tvalidation_0-auc:0.94149\tvalidation_1-aucpr:0.95436\tvalidation_1-auc:0.94246\n",
      "[19]\tvalidation_0-aucpr:0.95394\tvalidation_0-auc:0.94271\tvalidation_1-aucpr:0.95557\tvalidation_1-auc:0.94391\n",
      "[20]\tvalidation_0-aucpr:0.95394\tvalidation_0-auc:0.94271\tvalidation_1-aucpr:0.95557\tvalidation_1-auc:0.94391\n",
      "[21]\tvalidation_0-aucpr:0.95394\tvalidation_0-auc:0.94271\tvalidation_1-aucpr:0.95557\tvalidation_1-auc:0.94391\n",
      "[22]\tvalidation_0-aucpr:0.95394\tvalidation_0-auc:0.94271\tvalidation_1-aucpr:0.95557\tvalidation_1-auc:0.94391\n",
      "[23]\tvalidation_0-aucpr:0.95394\tvalidation_0-auc:0.94271\tvalidation_1-aucpr:0.95557\tvalidation_1-auc:0.94391\n",
      "[24]\tvalidation_0-aucpr:0.95427\tvalidation_0-auc:0.94355\tvalidation_1-aucpr:0.95572\tvalidation_1-auc:0.94430\n",
      "[25]\tvalidation_0-aucpr:0.95739\tvalidation_0-auc:0.94697\tvalidation_1-aucpr:0.95735\tvalidation_1-auc:0.94624\n",
      "[26]\tvalidation_0-aucpr:0.95771\tvalidation_0-auc:0.94740\tvalidation_1-aucpr:0.95757\tvalidation_1-auc:0.94665\n",
      "[27]\tvalidation_0-aucpr:0.95771\tvalidation_0-auc:0.94740\tvalidation_1-aucpr:0.95757\tvalidation_1-auc:0.94665\n",
      "[28]\tvalidation_0-aucpr:0.95808\tvalidation_0-auc:0.94782\tvalidation_1-aucpr:0.95808\tvalidation_1-auc:0.94713\n",
      "[29]\tvalidation_0-aucpr:0.95808\tvalidation_0-auc:0.94782\tvalidation_1-aucpr:0.95808\tvalidation_1-auc:0.94713\n",
      "[30]\tvalidation_0-aucpr:0.95817\tvalidation_0-auc:0.94808\tvalidation_1-aucpr:0.95816\tvalidation_1-auc:0.94734\n",
      "[31]\tvalidation_0-aucpr:0.95817\tvalidation_0-auc:0.94808\tvalidation_1-aucpr:0.95816\tvalidation_1-auc:0.94734\n",
      "[32]\tvalidation_0-aucpr:0.95817\tvalidation_0-auc:0.94808\tvalidation_1-aucpr:0.95816\tvalidation_1-auc:0.94734\n",
      "[33]\tvalidation_0-aucpr:0.95817\tvalidation_0-auc:0.94808\tvalidation_1-aucpr:0.95816\tvalidation_1-auc:0.94734\n",
      "[34]\tvalidation_0-aucpr:0.95831\tvalidation_0-auc:0.94839\tvalidation_1-aucpr:0.95848\tvalidation_1-auc:0.94782\n",
      "[35]\tvalidation_0-aucpr:0.95831\tvalidation_0-auc:0.94839\tvalidation_1-aucpr:0.95848\tvalidation_1-auc:0.94782\n",
      "[36]\tvalidation_0-aucpr:0.95831\tvalidation_0-auc:0.94839\tvalidation_1-aucpr:0.95848\tvalidation_1-auc:0.94782\n",
      "[37]\tvalidation_0-aucpr:0.95831\tvalidation_0-auc:0.94839\tvalidation_1-aucpr:0.95848\tvalidation_1-auc:0.94782\n",
      "[38]\tvalidation_0-aucpr:0.95831\tvalidation_0-auc:0.94839\tvalidation_1-aucpr:0.95848\tvalidation_1-auc:0.94782\n",
      "[39]\tvalidation_0-aucpr:0.95837\tvalidation_0-auc:0.94853\tvalidation_1-aucpr:0.95847\tvalidation_1-auc:0.94781\n",
      "[40]\tvalidation_0-aucpr:0.95847\tvalidation_0-auc:0.94885\tvalidation_1-aucpr:0.95883\tvalidation_1-auc:0.94837\n",
      "[41]\tvalidation_0-aucpr:0.95847\tvalidation_0-auc:0.94885\tvalidation_1-aucpr:0.95883\tvalidation_1-auc:0.94837\n",
      "[42]\tvalidation_0-aucpr:0.95851\tvalidation_0-auc:0.94879\tvalidation_1-aucpr:0.95876\tvalidation_1-auc:0.94824\n",
      "[43]\tvalidation_0-aucpr:0.95851\tvalidation_0-auc:0.94879\tvalidation_1-aucpr:0.95876\tvalidation_1-auc:0.94824\n",
      "[44]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[45]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[46]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[47]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[48]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[49]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[50]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[51]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[52]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[53]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[54]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[55]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[56]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[57]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[58]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[59]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[60]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[61]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[62]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[63]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[64]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[65]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[66]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[67]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[68]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[69]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[70]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[71]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[72]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n",
      "[73]\tvalidation_0-aucpr:0.95856\tvalidation_0-auc:0.94893\tvalidation_1-aucpr:0.95885\tvalidation_1-auc:0.94844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.01, gamma=10, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.8, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train,\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)], \n",
    "        eval_metric=['aucpr', 'auc'],  \n",
    "        early_stopping_rounds = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8815668202764977"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión:\n",
    "\n",
    "Se evidencia que al realizar la calibración del modelo teniendo en cuenta learning rate, gamma, colsample_bytree, logramos mejorar el accuracy con respecto a todos los modelos anteriormente realizados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión Car Price Prediction\n",
    "\n",
    "#### Modelo...............................................................Accuracy\n",
    "\n",
    "XGBoost Calibrado........................................... 0.88156682\n",
    "\n",
    "Ensamble 10 Arboles, Calibrar Max Features... 0.880645161\n",
    "\n",
    "Ensamble 10 Arboles, Max Features Log(p).....\t 0.880645161\n",
    "\n",
    "XGBoost Default............................................... 0.879032258\n",
    "\n",
    "Random Forest Calibrado\t................................ 0.877419355\n",
    "\n",
    "Ensamble 10 Arboles\t....................................... 0.8771889\n",
    "\n",
    "Arbol Decisión................................................... 0.872811\n",
    "\n",
    "Random Forest Default..................................... 0.838018433\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los resultados obtenidos podemos concluir que XGBoost calibrado es el modelo que mejor nos permite predecir el precio de un carro a partir de las variables del vehiculo.\n",
    "Adicionalmente, \n",
    "\n",
    "-los modelos calibrados funcionan muchisimo mejor que utilizarlos con sus valores default.\n",
    "\n",
    "-Los modelos con ensambles de arboles funcionan generalmente mejor que un arbol de decisión, ‘The wisdom of the crowd.’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
